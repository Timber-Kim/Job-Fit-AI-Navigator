import streamlit as st
import google.generativeai as genai
import pandas as pd
import os
import json

# ==========================================
# 1. ê¸°ë³¸ ì„¤ì • ë° ë°ì´í„° ë¡œë“œ
# ==========================================
st.set_page_config(page_title="Job-Fit AI", page_icon="ğŸ¤–", layout="wide")

try:
    GOOGLE_API_KEY = st.secrets["GOOGLE_API_KEY"]
except:
    GOOGLE_API_KEY = "ì—¬ê¸°ì—_API_í‚¤ë¥¼_ì…ë ¥í•˜ì„¸ìš”" # ë¡œì»¬ í…ŒìŠ¤íŠ¸ìš©

genai.configure(api_key=GOOGLE_API_KEY)

# ë°ì´í„° ë¡œë“œ í•¨ìˆ˜
@st.cache_data
def load_data():
    target_file = 'ai_tools.csv'
    # íƒì • ëª¨ë“œë¡œ íŒŒì¼ ì°¾ê¸°
    found_path = None
    for root, dirs, files in os.walk(os.getcwd()):
        if target_file in files:
            found_path = os.path.join(root, target_file)
            break
    
    if found_path is None:
        parent_dir = os.path.dirname(os.getcwd())
        for root, dirs, files in os.walk(parent_dir):
            if target_file in files:
                found_path = os.path.join(root, target_file)
                break

    if found_path is None: return None

    try:
        df = pd.read_csv(found_path, encoding='utf-8-sig', on_bad_lines='skip')
        return df
    except:
        try:
            df = pd.read_csv(found_path, encoding='cp949', on_bad_lines='skip')
            return df
        except:
            return None

df_tools = load_data()

# ==========================================
# 2. (í•µì‹¬ ê¸°ëŠ¥) AI ë‹µë³€ì„ CSV ë°ì´í„°ë¡œ ìë™ ë³€í™˜ ë° ì €ì¥
# ==========================================
def auto_save_to_csv(user_text, ai_text):
    """
    AIê°€ ëŒ€í™” ë‚´ìš©ì„ ë¶„ì„í•˜ì—¬ CSV ì–‘ì‹ì— ë§ëŠ” JSONìœ¼ë¡œ ë³€í™˜ í›„ ì €ì¥
    """
    try:
        # 1. ì •ë³´ë¥¼ ì¶”ì¶œí•˜ê¸° ìœ„í•œ ì „ìš© AI ëª¨ë¸ í˜¸ì¶œ
        extractor_model = genai.GenerativeModel('gemini-2.5-pro')
        
        extraction_prompt = f"""
        ë„ˆëŠ” 'ë°ì´í„° ì¶”ì¶œ ì „ë¬¸ê°€'ì•¼. ì•„ë˜ ëŒ€í™” ë‚´ìš©ì„ ë¶„ì„í•´ì„œ AI ë„êµ¬ ì •ë³´ë¥¼ JSON í˜•ì‹ìœ¼ë¡œ ì¶”ì¶œí•´ì¤˜.
        
        [ëŒ€í™” ë‚´ìš©]
        ì‚¬ìš©ì ì§ˆë¬¸: {user_text}
        AI ë‹µë³€: {ai_text}
        
        [ì¶”ì¶œí•  í•„ë“œ]
        - ì§ë¬´: (ì§ˆë¬¸ì—ì„œ ìœ ì¶”, ëª¨ë¥´ë©´ 'ê¸°íƒ€')
        - ìƒí™©: (ì§ˆë¬¸ ë‚´ìš© ìš”ì•½)
        - ê²°ê³¼ë¬¼: (ì§ˆë¬¸ì—ì„œ ìœ ì¶”, ì˜ˆ: ë³´ê³ ì„œ, ì´ë¯¸ì§€, PPT ë“±)
        - ì¶”ì²œë„êµ¬: (ë‹µë³€ì—ì„œ ì¶”ì²œí•œ í•µì‹¬ ë„êµ¬ ì´ë¦„ 1ê°œë§Œ)
        - íŠ¹ì§•_ë°_íŒ: (ë‹µë³€ ë‚´ìš© ìš”ì•½)
        - ìœ ë£Œì—¬ë¶€: (ë‹µë³€ì— ìˆìœ¼ë©´ ì‘ì„±, ì—†ìœ¼ë©´ 'í™•ì¸í•„ìš”')
        - ë§í¬: (ë‹µë³€ì— URLì´ ìˆë‹¤ë©´ ì¶”ì¶œ, ì—†ìœ¼ë©´ ë¹ˆì¹¸)

        ë°˜ë“œì‹œ ì˜¤ì§ JSON ë°ì´í„°ë§Œ ì¶œë ¥í•´. (Markdown íƒœê·¸ ì—†ì´)
        """
        
        # ì •ë³´ ì¶”ì¶œ ì‹¤í–‰
        result = extractor_model.generate_content(extraction_prompt)
        cleaned_json = result.text.replace("```json", "").replace("```", "").strip()
        data_dict = json.loads(cleaned_json)
        
        # 2. CSV íŒŒì¼ì— ì €ì¥
        file_path = 'ai_tools.csv'
        
        # ê¸°ì¡´ íŒŒì¼ ìœ„ì¹˜ ì°¾ê¸° (load_data ë¡œì§ ì¬ì‚¬ìš©í•˜ê±°ë‚˜ ê²½ë¡œ ê³ ì •)
        # í¸ì˜ìƒ í˜„ì¬ ì‘ì—… ê²½ë¡œ ìš°ì„  íƒìƒ‰
        if not os.path.exists(file_path):
             # ì—†ìœ¼ë©´ ìƒˆë¡œ ìƒì„±
             df_new = pd.DataFrame([data_dict])
             df_new.to_csv(file_path, index=False, encoding='utf-8-sig')
        else:
            # ìˆìœ¼ë©´ ì¶”ê°€
            df_old = pd.read_csv(file_path, encoding='utf-8-sig', on_bad_lines='skip')
            df_new = pd.DataFrame([data_dict])
            df_updated = pd.concat([df_old, df_new], ignore_index=True)
            df_updated.to_csv(file_path, index=False, encoding='utf-8-sig')
            
        return True, data_dict['ì¶”ì²œë„êµ¬']
        
    except Exception as e:
        return False, str(e)

# ==========================================
# 3. ì‚¬ì´ë“œë°” ë° ë©”ì¸ ì„¤ì •
# ==========================================
with st.sidebar:
    st.title("ğŸ›ï¸ ë©”ë‰´")
    if df_tools is not None:
        st.success(f"ë°ì´í„° ì—°ë™ë¨ ({len(df_tools)}ê°œ)")
    
    if st.button("ëŒ€í™” ì´ˆê¸°í™”"):
        st.session_state.messages = []
        st.rerun()

# AI ëª¨ë¸ ì„¤ì • (ë©”ì¸ ë‹µë³€ìš©)
csv_context = ""
if df_tools is not None:
    csv_context = f"[ë‚´ë¶€ ë°ì´í„°ë² ì´ìŠ¤]\n{df_tools.to_string(index=False)}"

sys_instruction = f"""
ë„ˆëŠ” ì§ë¬´ë³„ AI ë„êµ¬ ì¶”ì²œ ì „ë¬¸ê°€ì•¼. 
[ë‚´ë¶€ ë°ì´í„°ë² ì´ìŠ¤]ë¥¼ ìš°ì„  ì°¸ê³ í•˜ê³ , ì—†ìœ¼ë©´ ì™¸ë¶€ ì§€ì‹ì„ í™œìš©í•´.
ë‹µë³€ì—ëŠ” ë°˜ë“œì‹œ ë„êµ¬ ì´ë¦„, ì¶”ì²œ ì´ìœ , ìœ ë£Œ ì—¬ë¶€, ë§í¬ë¥¼ í¬í•¨í•´ì¤˜.
{csv_context}
"""
model = genai.GenerativeModel('gemini-2.5-pro', system_instruction=sys_instruction)

# ==========================================
# 4. ë©”ì¸ ì±„íŒ… ì¸í„°í˜ì´ìŠ¤
# ==========================================
st.title("ğŸš€ Job-Fit AI (ìë™í•™ìŠµ ë²„ì „)")
st.caption("ì§ˆë¬¸í•˜ê³  ğŸ‘ë¥¼ ëˆ„ë¥´ë©´, AIê°€ ìë™ìœ¼ë¡œ í•™ìŠµí•˜ì—¬ ë°ì´í„°ë² ì´ìŠ¤ì— ì¶”ê°€í•©ë‹ˆë‹¤.")

if "messages" not in st.session_state:
    st.session_state.messages = []

# ëŒ€í™” ë‚´ìš© í‘œì‹œ
for i, message in enumerate(st.session_state.messages):
    with st.chat_message(message["role"]):
        st.markdown(message["content"])
        
        # [í•µì‹¬] AIì˜ ë‹µë³€ì¸ ê²½ìš°ì—ë§Œ 'ì¢‹ì•„ìš”' ë²„íŠ¼ í‘œì‹œ
        if message["role"] == "assistant":
            # ì´ë¯¸ ì €ì¥ëœ ë©”ì‹œì§€ì¸ì§€ í™•ì¸í•˜ê¸° ìœ„í•œ í‚¤ ê´€ë¦¬ (ë²„íŠ¼ ì¤‘ë³µ í´ë¦­ ë°©ì§€ ë“±ì€ ì‹¬í™” êµ¬í˜„ í•„ìš”)
            col1, col2 = st.columns([1, 10])
            with col1:
                # ê³ ìœ í•œ key ìƒì„±ì„ ìœ„í•´ ì¸ë±ìŠ¤(i) ì‚¬ìš©
                if st.button("ğŸ‘", key=f"like_{i}", help="ì´ ë‹µë³€ì„ ë°ì´í„°ë² ì´ìŠ¤ì— ìë™ ì €ì¥"):
                    # ë°”ë¡œ ì§ì „ì˜ ì‚¬ìš©ì ì§ˆë¬¸ ì°¾ê¸°
                    user_query = st.session_state.messages[i-1]["content"] if i > 0 else "ì§ˆë¬¸ ì—†ìŒ"
                    ai_answer = message["content"]
                    
                    with st.spinner("ğŸ’¾ ë‹µë³€ ë‚´ìš©ì„ ë¶„ì„í•˜ì—¬ CSVì— ì €ì¥ ì¤‘..."):
                        success, tool_name = auto_save_to_csv(user_query, ai_answer)
                        if success:
                            st.toast(f"âœ… '{tool_name}' ì •ë³´ê°€ CSVì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤!", icon="ğŸ‰")
                            st.cache_data.clear() # ë°ì´í„° ê°±ì‹ ì„ ìœ„í•´ ìºì‹œ ì‚­ì œ
                        else:
                            st.error(f"ì €ì¥ ì‹¤íŒ¨: {tool_name}")

# ì‚¬ìš©ì ì…ë ¥ ì²˜ë¦¬
if prompt := st.chat_input("í•„ìš”í•œ AI ë„êµ¬ë¥¼ ë¬¼ì–´ë³´ì„¸ìš”"):
    st.session_state.messages.append({"role": "user", "content": prompt})
    st.rerun() # í™”ë©´ ê°±ì‹  í›„ ë‹µë³€ ìƒì„± ë¡œì§ìœ¼ë¡œ ì´ë™

# ë‹µë³€ ìƒì„± ë¡œì§
if st.session_state.messages and st.session_state.messages[-1]["role"] == "user":
    with st.chat_message("assistant"):
        with st.spinner("ë„êµ¬ë¥¼ ì°¾ëŠ” ì¤‘..."):
            chat_history = [{"role": m["role"], "parts": [m["content"]]} for m in st.session_state.messages if m["role"] != "system"]
            
            chat = model.start_chat(history=chat_history[:-1])
            response = chat.send_message(st.session_state.messages[-1]["content"])
            
            st.markdown(response.text)
            st.session_state.messages.append({"role": "assistant", "content": response.text})
            st.rerun() # ë‹µë³€ ì™„ë£Œ í›„ ë²„íŠ¼ì„ ê·¸ë¦¬ê¸° ìœ„í•´ ë‹¤ì‹œ ê°±ì‹ 