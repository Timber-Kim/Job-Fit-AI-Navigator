import streamlit as st
import pandas as pd
import gspread
from oauth2client.service_account import ServiceAccountCredentials
import datetime
from .config import SHEET_URL
# [ì¤‘ìš”] AI ë§¤ë‹ˆì €ì—ì„œ í‘œì¤€í™” í•¨ìˆ˜ ê°€ì ¸ì˜¤ê¸°
from .ai_manager import normalize_job_category

# êµ¬ê¸€ ì‹œíŠ¸ ì—°ê²°
@st.cache_resource
def connect_to_client():
    try:
        gcp_credentials = dict(st.secrets["gcp_service_account"])
        scope = ['https://spreadsheets.google.com/feeds', 'https://www.googleapis.com/auth/drive']
        creds = ServiceAccountCredentials.from_json_keyfile_dict(gcp_credentials, scope)
        client = gspread.authorize(creds)
        return client
    except Exception as e:
        st.error(f"êµ¬ê¸€ ì‹œíŠ¸ ì—°ê²° ì˜¤ë¥˜: {e}")
        return None

# ë°ì´í„° ë¡œë“œ
def load_db():
    client = connect_to_client()
    if not client: return pd.DataFrame()

    try:
        ws = client.open_by_url(SHEET_URL).get_worksheet(0)
        data = ws.get_all_records()
        
        if data:
            df = pd.DataFrame(data)
        else:
            df = pd.DataFrame(columns=['ì§ë¬´','ìƒí™©','ê²°ê³¼ë¬¼','ì¶”ì²œë„êµ¬','íŠ¹ì§•_ë°_íŒ','ìœ ë£Œì—¬ë¶€','ë§í¬','ë¹„ì¶”ì²œìˆ˜','ì¶”ì²œìˆ˜'])
        
        for col in ['ë¹„ì¶”ì²œìˆ˜', 'ì¶”ì²œìˆ˜']:
            if col not in df.columns: df[col] = 0
            df[col] = pd.to_numeric(df[col], errors='coerce').fillna(0).astype(int)
        
        return df
    except Exception as e:
        st.error(f"ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨: {e}")
        return pd.DataFrame()

# ë¡œê·¸ ì €ì¥
def save_log(job, situation, question, answer):
    try:
        client = connect_to_client()
        ws = client.open_by_url(SHEET_URL).get_worksheet(1)
        now = datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        ws.append_row([now, job, situation, question, answer])
    except:
        pass 

# DB ì—…ë°ì´íŠ¸ (ìë™ ì§ë¬´ í‘œì¤€í™” ì ìš©)
def update_db(action_type, tool_data, current_df):
    target = tool_data.get('ì¶”ì²œë„êµ¬')

    if not target: return False, "ì˜¤ë¥˜", current_df

    try:
        client = connect_to_client()
        ws = client.open_by_url(SHEET_URL).get_worksheet(0)
        
        # 1. ìµœì‹  ë°ì´í„° ê°€ì ¸ì˜¤ê¸° (ì¶©ëŒ ë°©ì§€)
        data = ws.get_all_records()
        df = pd.DataFrame(data) if data else current_df.copy()
        
        # 2. ìˆ«ìí˜• ì»¬ëŸ¼ ì•ˆì „ ì²˜ë¦¬
        for col in ['ë¹„ì¶”ì²œìˆ˜', 'ì¶”ì²œìˆ˜']:
            if col not in df.columns: df[col] = 0
            df[col] = pd.to_numeric(df[col], errors='coerce').fillna(0).astype(int)

        msg = ""
        updated = False

        # --- ë¡œì§ ì²˜ë¦¬ (ì¢‹ì•„ìš”/ì‹«ì–´ìš”) ---
        if action_type == 'like':
            if target in df['ì¶”ì²œë„êµ¬'].values:
                idx = df[df['ì¶”ì²œë„êµ¬'] == target].index[0]
                df.loc[idx, 'ì¶”ì²œìˆ˜'] += 1
                val_dislike = int(df.loc[idx, 'ë¹„ì¶”ì²œìˆ˜'])
                if val_dislike > 0: df.loc[idx, 'ë¹„ì¶”ì²œìˆ˜'] = val_dislike - 1
                msg = f"âœ¨ '{target}'ë¥¼ ì¶”ì²œí–ˆìŠµë‹ˆë‹¤!"
            else:
                # [ì‹ ê·œ ì¶”ê°€ ë¡œì§]
                input_job = tool_data.get('ì§ë¬´', 'ê¸°íƒ€')
                existing_jobs = [j for j in df['ì§ë¬´'].unique() if j != "ì§ì ‘ ì…ë ¥"]

                # ğŸ‘‡ ì—¬ê¸°ì„œ ì´ì œ 'ìƒíƒœë°”'ê°€ ëœ¨ë©´ì„œ ì•ˆì „í•˜ê²Œ ì‹¤í–‰ë©ë‹ˆë‹¤.
                standardized_job = normalize_job_category(input_job, existing_jobs)
                tool_data['ì§ë¬´'] = standardized_job

                # í•„ìˆ˜ê°’ ì´ˆê¸°í™”
                tool_data['ë¹„ì¶”ì²œìˆ˜'] = 0
                tool_data['ì¶”ì²œìˆ˜'] = 1
                
                # ë°ì´í„° í•©ì¹˜ê¸°
                df = pd.concat([df, pd.DataFrame([tool_data])], ignore_index=True)
                msg = f"ğŸ‰ '{target}' ë“±ë¡ ì™„ë£Œ! (ì§ë¬´: {standardized_job})"
            updated = True
        
        elif action_type == 'dislike':
            if target in df['ì¶”ì²œë„êµ¬'].values:
                idx = df[df['ì¶”ì²œë„êµ¬'] == target].index[0]
                val = int(df.loc[idx, 'ë¹„ì¶”ì²œìˆ˜']) + 1
                if val >= 3:
                    df = df.drop(idx).reset_index(drop=True)
                else:
                    df.loc[idx, 'ë¹„ì¶”ì²œìˆ˜'] = val
                msg = f"ğŸ“‰ ì˜ê²¬ì´ ë°˜ì˜ë˜ì—ˆìŠµë‹ˆë‹¤."
                updated = True
            else:
                return False, "SILENT", current_df

        # --- [í•µì‹¬ ìˆ˜ì • êµ¬ê°„: ì•ˆì „í•˜ê²Œ ì €ì¥í•˜ê¸°] ---
        if updated:
            # 1. NaN(ë¹ˆ ê°’) ì œê±° (ì´ê²Œ ì—†ìœ¼ë©´ JSON ì—ëŸ¬ë‚¨)
            df = df.fillna("") 
            
            # 2. ëª¨ë“  ë°ì´í„°ë¥¼ ë¬¸ìì—´ë¡œ ë³€í™˜ (ê°€ì¥ ê°•ë ¥í•œ ì•ˆì „ì¥ì¹˜)
            # ìˆ«ìê°€ ì„ì—¬ìˆê±°ë‚˜ Timestampê°€ ìˆìœ¼ë©´ gspreadê°€ ì—ëŸ¬ë¥¼ ë‚¼ ìˆ˜ ìˆìŒ
            df_for_upload = df.astype(str)

            # 3. ì—…ë¡œë“œí•  ë°ì´í„°ë¥¼ ë¦¬ìŠ¤íŠ¸ë¡œ 'ë¯¸ë¦¬' ë³€í™˜
            # (ì—¬ê¸°ì„œ ì—ëŸ¬ê°€ ë‚˜ë©´ ì‹œíŠ¸ëŠ” ê±´ë“œë¦¬ì§€ ì•Šê³  ë©ˆì¶¤ -> ë°ì´í„° ë³´ì¡´ë¨)
            payload = [df_for_upload.columns.values.tolist()] + df_for_upload.values.tolist()
            
            # 4. ë°ì´í„° ì¤€ë¹„ê°€ ì™„ë²½í•˜ê²Œ ëë‚œ í›„ì— ì‹œíŠ¸ ì´ˆê¸°í™” ë° ì—…ë°ì´íŠ¸
            ws.clear()
            ws.update(range_name='A1', values=payload) # ë¬¸ë²• í˜¸í™˜ì„± ê°œì„ 
            
            return True, msg, df
        
        return True, msg, df

    except Exception as e:
        # ì—ëŸ¬ê°€ ë‚˜ë„ ê¸°ì¡´ dfë¥¼ ë°˜í™˜í•´ì„œ í™”ë©´ì´ ê¹¨ì§€ì§€ ì•Šê²Œ í•¨
        print(f"Update DB Error: {e}") 
        return False, f"ì˜¤ë¥˜ ë°œìƒ: {e}", current_df

# ì§ë¬´ ë¦¬ìŠ¤íŠ¸ ë°˜í™˜ (Main.py ì‚¬ì´ë“œë°”ìš©)
def clean_job_titles():
    df = load_db()
    if df.empty: return []
    jobs = sorted(df['ì§ë¬´'].astype(str).str.strip().unique().tolist())
    return [j for j in jobs if j != "ì§ì ‘ ì…ë ¥"]